import os
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt
from env import TradingEnv
from agent import DQNAgent
from utils import load_and_process_data

# ðŸ“Š ZaÅ‚aduj rzeczywiste ceny i logarytmiczne zwroty
prices, log_returns = load_and_process_data('data/etf_prices_test_downward.csv')

# ðŸ¦ Inicjalizacja Å›rodowiska testowego
env = TradingEnv(prices, log_returns)
state_size = env._get_state().shape[0]
action_size = env.n_assets  

# ðŸ”„ Wczytaj wytrenowany model
MODEL_PATH = "dqn_trading_model.pth"
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"âŒ Brak modelu: {MODEL_PATH}. Najpierw wytrenuj model!")

agent = DQNAgent(state_size, action_size)
agent.load_model(MODEL_PATH)

# ðŸš€ WyÅ‚Ä…czamy eksploracjÄ™ (test = tylko strategia modelu)
agent.epsilon = 0.0  

# ðŸ”„ Parametry testu Monte Carlo
TEST_DAYS = 252 # ðŸ† Liczba dni testowych
N_SIMULATIONS = 100  # ðŸ† Liczba losowych testÃ³w

# ðŸ“Š Inicjalizacja wynikÃ³w Monte Carlo
best_value = float('-inf')
worst_value = float('inf')
best_trades = None
worst_trades = None
final_portfolio_values = []
total_rewards = []

# ðŸ”„ Symulacje Monte Carlo
for sim in range(N_SIMULATIONS):
    START_INDEX = np.random.randint(0, len(prices) - TEST_DAYS)

    # ðŸ”„ Reset Å›rodowiska przed kaÅ¼dÄ… symulacjÄ…
    env.start_step = START_INDEX
    env.current_step = START_INDEX
    env.episode_length = TEST_DAYS
    state = env.reset(episode_length=TEST_DAYS)
    
    done = False
    total_reward = 0

    while not done:
        action = agent.act(state)  
        next_state, reward, done = env.step(action)

        state = next_state
        total_reward += reward

    final_value = env._get_portfolio_value()
    final_portfolio_values.append(final_value)
    total_rewards.append(total_reward)

    # ðŸ” Sprawdzenie najlepszej symulacji
    if final_value > best_value:
        best_value = final_value
        best_trades = env.trades.copy()  # âœ… Zapisujemy kopiÄ™ listy transakcji

    # ðŸ”» Sprawdzenie najgorszej symulacji
    if final_value < worst_value:
        worst_value = final_value
        worst_trades = env.trades.copy()  # âœ… Zapisujemy kopiÄ™ listy transakcji

    print(f"ðŸ”„ Symulacja {sim+1}/{N_SIMULATIONS} | ðŸŽ¯ Nagroda: {total_reward:.2f} | ðŸ’° Portfel: {final_value:.2f}")

# ðŸ“Š Podsumowanie Monte Carlo
mean_value = np.mean(final_portfolio_values)
std_value = np.std(final_portfolio_values)
mean_reward = np.mean(total_rewards)
std_reward = np.std(total_rewards)

print("\nðŸ“Š Wyniki Monte Carlo:")
print(f"ðŸ’° Åšrednia koÅ„cowa wartoÅ›Ä‡ portfela: ${mean_value:.2f} Â± {std_value:.2f}")
print(f"ðŸŽ¯ Åšrednia nagroda: {mean_reward:.2f} Â± {std_reward:.2f}")
print(f"ðŸ† Najlepsza symulacja: {best_value:.2f} | ðŸ“‰ Najgorsza symulacja: {worst_value:.2f}")

# ðŸ† Zapisujemy tylko najlepszÄ… i najgorszÄ… symulacjÄ™
def save_trades(trades, filename):
    if trades:
        df = pd.DataFrame(trades, columns=["Date", "ETF_ID", "Action", "Price", "Shares", "Cash Before", "Cash After", "Portfolio Value", "Action Value", "Currently Held"])
        df = df.drop_duplicates()  # âœ… Usuwamy duplikaty przed zapisem
        df.to_csv(filename, index=False)
        print(f"âœ… Transakcje zapisane: {filename}")

save_trades(best_trades, "./monte_carlo/MonteCarlo_Best.csv")
save_trades(worst_trades, "./monte_carlo/MonteCarlo_Worst.csv")

# ðŸ“ˆ Wizualizacja wynikÃ³w Monte Carlo
fig, axes = plt.subplots(2, 1, figsize=(10, 10))

# ðŸ“‰ Histogram koÅ„cowych wartoÅ›ci portfela
axes[0].hist(final_portfolio_values, bins=20, color="blue", alpha=0.7, edgecolor="black")
axes[0].set_title("Histogram koÅ„cowej wartoÅ›ci portfela")
axes[0].set_xlabel("WartoÅ›Ä‡ portfela ($)")
axes[0].set_ylabel("Liczba symulacji")

# ðŸ“Š Histogram nagrÃ³d
axes[1].hist(total_rewards, bins=20, color="green", alpha=0.7, edgecolor="black")
axes[1].set_title("Histogram sumarycznej nagrody")
axes[1].set_xlabel("Nagroda")
axes[1].set_ylabel("Liczba symulacji")

plt.tight_layout()
plt.show()
